{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazsa6/Learning-Deep-Learning/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b85b17f-5b53-4ee2-9e01-1a6e5250758c",
      "metadata": {
        "id": "3b85b17f-5b53-4ee2-9e01-1a6e5250758c"
      },
      "source": [
        "## Phi-3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcab8efd-4224-4c1c-be36-354b3398337c",
      "metadata": {
        "id": "fcab8efd-4224-4c1c-be36-354b3398337c"
      },
      "source": [
        "# 1. Setup: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ac8022df-dc66-452f-b977-6487b60afaed",
      "metadata": {
        "id": "ac8022df-dc66-452f-b977-6487b60afaed"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6677b8ea-cefc-403b-9730-58cc42022221",
      "metadata": {
        "id": "6677b8ea-cefc-403b-9730-58cc42022221"
      },
      "source": [
        "# 2. Manual Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "420dbe4c-7c47-4a95-a17a-c63afe6fea24",
      "metadata": {
        "id": "420dbe4c-7c47-4a95-a17a-c63afe6fea24"
      },
      "source": [
        "## 2.1. Load Model and Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1b458554-de6c-432e-8942-6fab60224ccb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "38ab9a5c96e54f65b1c4fbbdea9d1320",
            "ff5976beaa504d418dc8ee9a2c83f24b",
            "4668d82d62d74a7d8fffb34fb05ecbf6",
            "b3ab9355a8504d71bd8dd100bc727fac",
            "181b1d9e9d9f467886308a367405bdc3",
            "704d5bbbbab4460b813761d0dc0fc6cd",
            "5ec1a518c5cf4886beb70f46510126d9",
            "bd5a38cab67245de84296694805adf67",
            "13aa65b706534ec1a1ba27d5dcb89806",
            "67b9f563ab32458daeb46125ebac0732",
            "b1a10cdd3594459b8cec80f8bead4406"
          ]
        },
        "id": "1b458554-de6c-432e-8942-6fab60224ccb",
        "outputId": "bf7fd34b-7c7b-4166-99ea-a64af127661d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "38ab9a5c96e54f65b1c4fbbdea9d1320"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "# Load the causal language model\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=False,\n",
        ")\n",
        "\n",
        "# Load the tokenizer for the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96d53c72-55be-4917-8d44-d60cdeeaf5fd",
      "metadata": {
        "id": "96d53c72-55be-4917-8d44-d60cdeeaf5fd"
      },
      "source": [
        "## 2.2. Tokenization Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9fce2f45-9910-4510-aec9-75b2219f4401",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fce2f45-9910-4510-aec9-75b2219f4401",
        "outputId": "8a0ab1af-12e5-4724-ef53-c0384625f378"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "910 --> ▁This\n",
            "338 --> ▁is\n",
            "777 --> ▁some\n",
            "1426 --> ▁text\n",
            "304 --> ▁to\n",
            "5993 --> ▁token\n",
            "675 --> ize\n",
            "29889 --> .\n"
          ]
        }
      ],
      "source": [
        "# Define the text variable\n",
        "text = \"This is some text to tokenize.\"\n",
        "\n",
        "# Encode text into input IDs\n",
        "encoding = tokenizer(text)\n",
        "\n",
        "# Convert input IDs to readable tokens\n",
        "tokens = tokenizer.convert_ids_to_tokens(encoding['input_ids'])\n",
        "\n",
        "# Print token IDs and their corresponding tokens\n",
        "for token_id, token_str in zip(encoding['input_ids'], tokens):\n",
        "    print(f\"{token_id} --> {token_str}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3576b2f-23f1-426d-8e62-14a36bf93494",
      "metadata": {
        "id": "c3576b2f-23f1-426d-8e62-14a36bf93494"
      },
      "source": [
        "## 2.3. Model Inference (Logits and Prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e0a344a1-04c5-4520-847d-b7da301e70c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0a344a1-04c5-4520-847d-b7da301e70c3",
        "outputId": "c9a58ab8-42b6-4912-a57c-3c75665b6200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(40.7500, device='cuda:0', dtype=torch.bfloat16, grad_fn=<MaxBackward1>)\n",
            "tensor(52.2500, device='cuda:0', dtype=torch.bfloat16, grad_fn=<MaxBackward1>)\n",
            "tensor(338, device='cuda:0')\n",
            "tensor(263, device='cuda:0')\n",
            ",!\n",
            "is a code. testize.\n",
            "\n",
            "is a code. testize.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tokenize and move input to same device as model\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# Get raw output logits from model\n",
        "outputs = model(**inputs)\n",
        "\n",
        "# Print max logit values (confidence per token position)\n",
        "print(outputs.logits[0][0].max())  # For first token\n",
        "print(outputs.logits[0][1].max())  # For second token\n",
        "\n",
        "# Print predicted token IDs (most likely next token at each position)\n",
        "print(outputs.logits[0][0].argmax())  # ID of most likely first token\n",
        "print(outputs.logits[0][1].argmax())  # ID of most likely second token\n",
        "\n",
        "# Decode a couple of token IDs manually\n",
        "print(tokenizer.decode([29892, 29991]))\n",
        "print(tokenizer.decode(outputs.logits[0].argmax(-1)))\n",
        "\n",
        "# Full predicted token sequence from logits\n",
        "predicted_token_id = outputs.logits.argmax(dim=-1)\n",
        "print(tokenizer.decode(predicted_token_id[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac5eff03-2bb8-4d15-9288-9d24436f23e3",
      "metadata": {
        "id": "ac5eff03-2bb8-4d15-9288-9d24436f23e3"
      },
      "source": [
        "## 2.4. Generate continuation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "525fb8d7-8d13-43dc-93f0-db6fe5e2aefb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "525fb8d7-8d13-43dc-93f0-db6fe5e2aefb",
        "outputId": "5adc469a-3bb3-4dd7-ee1f-fa526fbc0ca4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is some text to tokenize. tokenize.\"\n",
            "print(\"Original text: \", original_text)\n",
            "print(\"\\nTokenized\n"
          ]
        }
      ],
      "source": [
        "# Generate continuation\n",
        "generated_ids = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    #max_new_tokens=50,       # Number of tokens to generate\n",
        "    do_sample=True,         # Use greedy decoding (set True for randomness)\n",
        "    pad_token_id=tokenizer.eos_token_id  # Avoid warning if eos is not set\n",
        ")\n",
        "\n",
        "# Decode and print result\n",
        "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14017ff5-6267-4648-8352-0e5918ebaeec",
      "metadata": {
        "id": "14017ff5-6267-4648-8352-0e5918ebaeec"
      },
      "source": [
        "# 3. Pipeline Path"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3192d2b-3669-4c7b-b5a2-2318a8895fad",
      "metadata": {
        "id": "b3192d2b-3669-4c7b-b5a2-2318a8895fad"
      },
      "source": [
        "## 3.1. Pipeline Preparation"
      ]
    },
    {
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4FSiHpJY73k_"
      },
      "id": "4FSiHpJY73k_",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ec88d546-0390-41e4-9af6-e8d271a73899",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec88d546-0390-41e4-9af6-e8d271a73899",
        "outputId": "594c0d84-1abe-4e6a-d752-649d6e292beb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda\n"
          ]
        }
      ],
      "source": [
        "# Create a text-generation pipeline using the same model and tokenizer\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=False,\n",
        "    max_new_tokens=500,   # Limit length of generated text\n",
        "    do_sample=False       # Deterministic (no sampling)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2ff5493-86d9-4785-b703-89432b810d3e",
      "metadata": {
        "id": "d2ff5493-86d9-4785-b703-89432b810d3e"
      },
      "source": [
        "## 3.2. Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a64c4ebd-b22b-49d4-9668-36c7b6d5f168",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a64c4ebd-b22b-49d4-9668-36c7b6d5f168",
        "outputId": "ebb81e5f-c2f7-4987-9d2e-23fbe3703126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " This is a simple greeting in English, equivalent to the given Chinese greeting \"你好，世界\" (Hello, World). It's a common phrase used to greet someone or to acknowledge the presence of the world in a general sense.\n"
          ]
        }
      ],
      "source": [
        "# Prompt for the model\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Hello World\"}\n",
        "]\n",
        "\n",
        "# Generate text using the prompt\n",
        "output = generator(messages)\n",
        "\n",
        "# Print generated output\n",
        "print(output[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b22261cc-abf1-47a0-9835-359b50356469",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b22261cc-abf1-47a0-9835-359b50356469",
        "outputId": "cf804939-1031-4181-83f2-8ec8719ff4de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Why did the chicken join the band? Because it had the drumsticks!\n"
          ]
        }
      ],
      "source": [
        "# The prompt (user input / query)\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n",
        "]\n",
        "\n",
        "# Generate output\n",
        "output = generator(messages)\n",
        "print(output[0][\"generated_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: get image for this chatbot\n",
        "\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# Option 1: Display an image from Google Drive\n",
        "# Make sure you have mounted your Google Drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# display(Image('/content/drive/My Drive/chatbot_image.png'))\n",
        "\n",
        "# Option 2: Display an image from a URL\n",
        "# Replace with the actual URL of the image\n",
        "image_url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/200px-ChatGPT_logo.svg.png'\n",
        "display(Image(url=image_url))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "YBIrTn3yCCxD",
        "outputId": "38efeeb4-542a-410f-fe21-37653e4c4f2a"
      },
      "id": "YBIrTn3yCCxD",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/200px-ChatGPT_logo.svg.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e680e95-d758-4bdb-9f11-1075130a38d6",
      "metadata": {
        "id": "9e680e95-d758-4bdb-9f11-1075130a38d6"
      },
      "source": [
        "## 3.3. Small Chatbot! Enjoy!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d670867-6a00-41f3-b04d-1fecdb0ad5a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d670867-6a00-41f3-b04d-1fecdb0ad5a5",
        "outputId": "7fc79da3-8988-457e-eeab-44d44e48152c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot is ready! Type 'exit' to quit.\n",
            "\n",
            "You: get image for chatgpt\n",
            "Bot:  I'm sorry, but I can't assist with that request.\n",
            "You: How can i get images?\n",
            "Bot:  There are several ways to obtain images for use in a chatbot or any other application. Here are some options:\n",
            "\n",
            "1. Public domain images: Websites like Unsplash, Pixabay, and Pexels offer high-quality images that are free to use for personal and commercial purposes.\n",
            "\n",
            "2. Stock photo websites: Websites like Shutterstock, Adobe Stock, and Getty Images offer a wide range of images for purchase.\n",
            "\n",
            "3. Creative Commons images: Websites like Wikimedia Commons and Flickr have a large collection of images that are available under Creative Commons licenses. You'll need to check the specific license for each image to ensure you're using it in compliance with the terms.\n",
            "\n",
            "4. Create your own images: If you have the skills and resources, you can create your own images using graphic design software like Adobe Photoshop or Illustrator.\n",
            "\n",
            "5. Use images from chatbot platforms: Some chatbot platforms, like Microsoft's Bot Framework, offer a library of images that you can use in your chatbot.\n",
            "\n",
            "Remember to always give credit to the original creator of the image if you're using it for commercial purposes, and respect the terms of the license under which the image is provided.\n",
            "You: can you give me image here?\n",
            "Bot:  I'm sorry, but I can't assist with that request.\n"
          ]
        }
      ],
      "source": [
        "# Store chat history\n",
        "messages = []\n",
        "\n",
        "print(\"Chatbot is ready! Type 'exit' to quit.\\n\")\n",
        "\n",
        "while True:\n",
        "    # Get user input\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print('Conversation has ended!')\n",
        "        break\n",
        "\n",
        "    # Add user message to history\n",
        "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Generate model response\n",
        "    response = generator(messages)\n",
        "\n",
        "    # Get the assistant reply\n",
        "    reply = response[0][\"generated_text\"]\n",
        "    print(\"Bot:\", reply)\n",
        "\n",
        "    # Add assistant reply to history\n",
        "    messages.append({\"role\": \"assistant\", \"content\": reply})"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "eocv",
      "language": "python",
      "name": "eocv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "38ab9a5c96e54f65b1c4fbbdea9d1320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff5976beaa504d418dc8ee9a2c83f24b",
              "IPY_MODEL_4668d82d62d74a7d8fffb34fb05ecbf6",
              "IPY_MODEL_b3ab9355a8504d71bd8dd100bc727fac"
            ],
            "layout": "IPY_MODEL_181b1d9e9d9f467886308a367405bdc3"
          }
        },
        "ff5976beaa504d418dc8ee9a2c83f24b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_704d5bbbbab4460b813761d0dc0fc6cd",
            "placeholder": "​",
            "style": "IPY_MODEL_5ec1a518c5cf4886beb70f46510126d9",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "4668d82d62d74a7d8fffb34fb05ecbf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd5a38cab67245de84296694805adf67",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13aa65b706534ec1a1ba27d5dcb89806",
            "value": 2
          }
        },
        "b3ab9355a8504d71bd8dd100bc727fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67b9f563ab32458daeb46125ebac0732",
            "placeholder": "​",
            "style": "IPY_MODEL_b1a10cdd3594459b8cec80f8bead4406",
            "value": " 2/2 [00:19&lt;00:00,  8.72s/it]"
          }
        },
        "181b1d9e9d9f467886308a367405bdc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "704d5bbbbab4460b813761d0dc0fc6cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec1a518c5cf4886beb70f46510126d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd5a38cab67245de84296694805adf67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13aa65b706534ec1a1ba27d5dcb89806": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67b9f563ab32458daeb46125ebac0732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1a10cdd3594459b8cec80f8bead4406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}